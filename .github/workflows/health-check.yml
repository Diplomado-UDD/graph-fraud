name: Health Check

on:
  push:
    branches: [ main ]
  workflow_dispatch:

jobs:
  health-check:
    runs-on: ubuntu-latest
    timeout-minutes: 90
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install uv (project package manager)
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          export PATH="$HOME/.local/bin:$PATH"

      - name: Run unit tests & coverage
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          # Run tests with coverage and produce HTML report
          uv run pytest --maxfail=1 -q --cov=src --cov-report=html:htmlcov

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: htmlcov

      - name: Build and start stack with Docker Compose
        run: |
          docker compose up -d --build
          # give services a little more time to initialize before health checks
          sleep 60

      - name: Run health check script (with retries)
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          # Retry the health-check several times to allow services to finish booting.
          MAX_RETRIES=30
          SLEEP_SECONDS=10
          PASSED=0
          for i in $(seq 1 $MAX_RETRIES); do
            echo "Health check attempt $i/$MAX_RETRIES"
            if uv run python scripts/check_system_health.py > health-report.txt 2>&1; then
              echo "Health check passed on attempt $i"
              PASSED=1
              break
            else
              echo "Health check failed on attempt $i, sleeping $SLEEP_SECONDS seconds"
              sleep $SLEEP_SECONDS
            fi
          done
          if [ "$PASSED" -ne 1 ]; then
            echo "Health check did not pass after $MAX_RETRIES attempts. Last report:"
            cat health-report.txt || true
            exit 1
          fi

      - name: Export MLflow runs
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          uv run python scripts/export_mlflow_runs.py

      - name: Run training pipeline (integration)
        run: |
          # Run training inside the graph-rag-api container with a timeout to avoid long-running jobs
          # If training exceeds 20 minutes the step will fail.
          timeout 20m docker compose run --rm -e MLFLOW_TRACKING_URI=http://fraud-mlflow:5000 graph-rag-api uv run python scripts/train_fraud_detector.py

      - name: Run batch scoring (integration)
        run: |
          # Batch scoring should also be bounded; use a 10 minute timeout
          timeout 10m docker compose run --rm -e MLFLOW_TRACKING_URI=http://fraud-mlflow:5000 graph-rag-api uv run python scripts/batch_scoring.py

      - name: Export MLflow runs (post-integration)
        run: |
          export PATH="$HOME/.local/bin:$PATH"
          uv run python scripts/export_mlflow_runs.py

      - name: Upload MLflow export (post-integration)
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-runs-post-integration
          path: outputs/mlflow_runs.json

      - name: Upload scoring outputs
        uses: actions/upload-artifact@v4
        with:
          name: scoring-outputs
          path: outputs/

      - name: Upload MLflow export
        uses: actions/upload-artifact@v4
        with:
          name: mlflow-runs
          path: outputs/mlflow_runs.json

      - name: Upload health report
        uses: actions/upload-artifact@v4
        with:
          name: health-report
          path: health-report.txt

      - name: Collect Docker diagnostics on failure
        if: failure()
        run: |
          echo "Collecting docker-compose status and container logs..."
          docker compose ps --all > docker-compose-ps.txt || true
          # collect combined logs (no color) for all services (tail to avoid huge uploads)
          docker compose logs --no-color --tail=1000 > docker-compose-logs.txt || true
          # collect per-service logs if present (best-effort)
          SERVICES="fraud-neo4j fraud-mlflow graph-rag-api prometheus grafana"
          for s in $SERVICES; do
            echo "Collecting logs for $s"
            docker compose logs --no-color --tail=200 $s > "logs_${s}.txt" || true
          done
        shell: bash

      - name: Upload docker diagnostics
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: docker-diagnostics
          path: |
            docker-compose-ps.txt
            docker-compose-logs.txt
            logs_fraud-neo4j.txt
            logs_fraud-mlflow.txt
            logs_graph-rag-api.txt
            logs_prometheus.txt
            logs_grafana.txt
